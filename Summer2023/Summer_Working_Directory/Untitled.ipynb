{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9150c409-3073-4099-a28a-e4109a146a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "### Reding csv file containing 243 subjects and their raw TPM counts across 1059 genes\n",
    "### Source of data\n",
    "myDF = pd.read_excel(\"C:/Users/filip/OneDrive/Desktop/Molecular Stethoscope/Summer/ClusterMarkers_1819ADcohort.xlsx\", sheet_name = 1)\n",
    "# setting index row name to the gene id\n",
    "myDF = myDF.set_index('gene_id')\n",
    "\n",
    "#Filtering out rows: discarding the ERCC rows, ERCC is a control protocol for validation of RNA sequencing\n",
    "Patients_df = myDF[~myDF.loc[:,'Coeff'].isnull()]\n",
    "\n",
    "# We store the coefficients(betas) of the linear classifier in an array.\n",
    "coefficients = np.nan_to_num(np.array(Patients_df.loc[:, \"Coeff\"]))\n",
    "\n",
    "# Filtering out columns with patient data\n",
    "Patients_df = Patients_df.filter(regex='^\\d+')\n",
    "\n",
    "# group columns by patient id\n",
    "grouped_cols = Patients_df.columns.str.split('-').str[0]\n",
    "\n",
    "# group columns by patient id and r1/r2 suffixes\n",
    "grouped = Patients_df.groupby(grouped_cols, axis=1)\n",
    "\n",
    "# apply the mean function to the r1 and r2 columns for each group\n",
    "# taking mean of the replicates for subjects with multiple replicates\n",
    "Patients_df = grouped.apply(lambda x: x.mean(axis=1)).reset_index(drop=True)\n",
    "# Patients_df.head()\n",
    "\n",
    "Patients_df['Mean']= Patients_df.mean(axis=1)\n",
    "Patients_df['Std']=Patients_df.iloc[:,:-1].std(axis=1)\n",
    "Patients_df['RSD'] = (Patients_df['Std'] / Patients_df['Mean']) # New code Filip\n",
    "Patients_df.head()\n",
    "#print(Patients_df.shape)\n",
    "\n",
    "# We define a function whose input is TPM and outputs the corresponding Zscore\n",
    "def z_score(x):\n",
    "    return (x-x['Mean'])/x['Std']\n",
    "\n",
    "# Computing and storing zscores\n",
    "Patients_df_zScore = Patients_df.apply(lambda x: z_score(x), axis=1)\n",
    "Patients_df_zScore.head()\n",
    "#print(Patients_df_zScore.shape)\n",
    "\n",
    "patient_id= list(Patients_df_zScore.columns.values)\n",
    "patient_id = patient_id[0:243]\n",
    "#patient_id\n",
    "\n",
    "#np.random.seed(46215423)\n",
    "\n",
    "# Sampling function performing the Monte Carlo simulations\n",
    "def Simulation(means, std, coefficients):\n",
    "    return np.sum(np.multiply(coefficients, np.random.normal(means, std, size=(1, len(coefficients)))))\n",
    "\n",
    "# Function to perform anti-logit operation on the linear score \n",
    "def cl_score(linear_score, gamma = 0):\n",
    "    temp = gamma + linear_score\n",
    "    classifier_score = np.exp(temp) / (1 + np.exp(temp))\n",
    "    return classifier_score\n",
    "\n",
    "# Function to calculate subject wise mean and std of simulated scores \n",
    "def run_sim_one_patient_mean_sd(col,percent):\n",
    "    std = [percent/100 * val for val in col]\n",
    "    std = np.abs(std)\n",
    "    temp_Sim = [Simulation(col, std, coefficients) for _ in range(numRuns)]\n",
    "    return [np.mean(temp_Sim),np.std(temp_Sim)]\n",
    "\n",
    "# Function to calculate the classifier score for each simulation of \"num_runs\" simulations, corresponding to each subject\n",
    "def run_sim_one_patient(col, percent, num_runs):\n",
    "    std = [percent/100 * val for val in col]\n",
    "    std = np.abs(std)\n",
    "    temp_Sim = np.asarray([cl_score(Simulation(col, std, coefficients)) for _ in range(num_runs)])\n",
    "    return temp_Sim\n",
    "\n",
    "# This score is the classifer linear score we want to compare with the simulated scores\n",
    "def linear_score(coefficients, col):\n",
    "    linear_score = np.sum(coefficients * col, axis=0)\n",
    "    return linear_score\n",
    "\n",
    "num_runs = 1000\n",
    "uncertainty = 25\n",
    "thresh = 0.04874941\n",
    "\n",
    "def plot_uncert_at_thresh(num_runs , uncertainty, thresh ):\n",
    "    \n",
    "    \n",
    "    \"\"\"The purpose of this function is to produce 2 things based on %RSD (uncertainty), threshold (thresh), number of MC simulations (num_runs) :\n",
    "    1. Figure to show the scattering based on classifier scores of simulations against subject.\n",
    "    2. False Positves/Negatives\n",
    "    \n",
    "    pseudocode:\n",
    "    1.  for a range of %RSD, the code starts with the first %RSD.\n",
    "    2a. for each subject, it calculates the linear score by multiplying the z-scores present in dataframe \"Patients_df_zScore\"  by coefficient. Function used: linear_score\n",
    "    2b. then it performs anti-logit operation on the linear score to get the classifier score.  Function used: cl_score \n",
    "    3.  similarly, \"scores\" stores the classifier score for each simulation of \"num_runs\"simulations, corresponding to each subject. Function used: run_sim_one_patient\n",
    "    4a. since, we will plot the simulation scores against the subject scores, x_data creates the same array shape for subject scores as simulation scores.\n",
    "    4b. y_data is just scores for the simplicity.\n",
    "    5.  Now coming to each simuation score in each subject: we will sort out the simulation as FP, FN, TP, TN based on threshold using if-else condtions. this code \n",
    "        will run for num_runs.\n",
    "    6.  based on FP, FN, TP, TN we will calculate the accuracy.\n",
    "    7.  the process 2-6 will be repeated for each subject.\n",
    "    8.  A scatter plot will be produced using simulation scores on y-axis and subject scores on x-axis, two perpendicular lines passing the thresholds on x and y axis\n",
    "     will  categorize the scatter dots into FP, FN , TP and TN.\n",
    "    \n",
    "    \n",
    "    Example input: sub_accuracy(400, 50, 0.87)\n",
    "    \"\"\"\n",
    "    \n",
    "    false_pos = 0 # counter, stores number of points on second quadrant\n",
    "    false_neg = 0\n",
    "    num_subj_unreliable = np.zeros(243) # keeps track of subjects whose score is unreliable under the assumed variation (0 is fine, 1 is unreliable)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    #for i in range(243):\n",
    "    for i in range(243):\n",
    "        scores = run_sim_one_patient(Patients_df_zScore.iloc[:, i], uncertainty, num_runs)\n",
    "        y_0 = cl_score(linear_score(coefficients, Patients_df_zScore.iloc[:, i]))\n",
    "        x_data = np.ones_like(scores) * y_0\n",
    "        y_data = scores\n",
    "        colour = np.zeros_like(x_data)\n",
    "        for j in range(len(x_data)):\n",
    "            if x_data[j] > thresh and y_data[j] < thresh:\n",
    "                colour[j] = 1\n",
    "                false_neg = false_neg + 1\n",
    "                num_subj_unreliable[i] = 1\n",
    "            elif x_data[j] < thresh and y_data[j]> thresh:\n",
    "                colour[j] = 2\n",
    "                false_pos = false_pos + 1\n",
    "                num_subj_unreliable[i] = 1\n",
    "        plt.scatter(x_data, y_data, c=colour, cmap = 'Dark2_r' ,alpha = 0.15, s=100)\n",
    "    plt.axvline(x = thresh, color = 'g', linestyle= '--')\n",
    "    plt.axhline(y = thresh, color = 'g', linestyle= '--')\n",
    "    #plt.xlim([0.425, 0.575])\n",
    "    #plt.ylim([0.425, 0.575])\n",
    "    plt.xlabel(\"Classifier score\", fontsize= 24)\n",
    "    plt.ylabel(\"Simulated scores\", fontsize = 24)\n",
    "    plt.title('Uncertainty around threshold', fontsize = 28)\n",
    "    # Below are the labels of agreement and disagreement\n",
    "    A = plt.scatter([0],[0], alpha =0) # dummy plot for legend\n",
    "    B = plt.scatter([0],[0],  alpha =0) # dummy plot for legend\n",
    "    plt.text(0, 0.8, 'A', fontsize = 20)\n",
    "    plt.text(0, 0, 'B', fontsize =20)\n",
    "    plt.text(0.8, 0, 'B', fontsize =20)\n",
    "    plt.text(0.8, 0.8, 'A', fontsize =20)\n",
    "    plt.legend([A,B], ['A : Agreement', 'B : Disagreement'])\n",
    "    #plt.savefig('figures/uncert_around_thresh_25_RSD.png')\n",
    "\n",
    "    return [ fig , false_pos , false_neg , (np.sum(num_subj_unreliable)) ]\n",
    "\n",
    "cl_score(-2.97108439) # checking the threshold value in probability\n",
    "\n",
    "### Check that random seeding is working by running this cell several times... it is working.\n",
    "np.random.seed(2)\n",
    "scores = run_sim_one_patient(Patients_df_zScore.iloc[:, 1], uncertainty, num_runs)\n",
    "print(scores)\n",
    "len(scores)\n",
    "\n",
    "# Example for using the above function\n",
    "plot_uncert_at_thresh(100,50,0.86)\n",
    "plot_uncert_at_thresh(num_runs,uncertainty,thresh)\n",
    "\n",
    "def sub_accuracy(uncertainty_range, thresh, num_runs):\n",
    "    \"\"\"The purpose of this function is to calculate 2 things based on %RSD (uncertainty_range), threshold (thresh), number of MC simulations (num_runs) :\n",
    "    1. subject accuracy based on number of simulations : this info is provided in a dataframe called \"accuracy_df\"\n",
    "    2. True Positives/Negatives, False Positves/Negatives: this info is provided in a dtatframe called \"false_pos_df\"\n",
    "    \n",
    "    pseudocode:\n",
    "    1.  for a range of %RSD, the code starts with the first %RSD.\n",
    "    2a. for each subject, it calculates the linear score by multiplying the z-scores present in dataframe \"Patients_df_zScore\"  by coefficient. Function used: linear_score\n",
    "    2b. then it performs anti-logit operation on the linear score to get the classifier score.  Function used: cl_score \n",
    "    3.  similarly, \"scores\" stores the classifier score for each simulation of \"num_runs\"simulations, corresponding to each subject. Function used: run_sim_one_patient\n",
    "    4a. since, we will plot the simulation scores against the subject scores, x_data creates the same array shape for subject scores as simulation scores.\n",
    "    4b. y_data is just scores for the simplicity.\n",
    "    5.  Now coming to each simuation score in each subject: we will sort out the simulation as FP, FN, TP, TN based on threshold using if-else condtions. this code will run for num_runs.\n",
    "    6.  based on FP, FN, TP, TN we will calculate the accuracy.\n",
    "    7.  the process 2-6 will be repeated for each subject.\n",
    "    8.  the process 2-7 will be repeated for each %RSD input. \n",
    "    \n",
    "    \n",
    "    Example input: sub_accuracy([20, 40, 50], 0.87, 400)  -> note that uncertainty_range should be given in a form of a list even if giving single value.\n",
    "    \"\"\"\n",
    "    global real_score\n",
    "    global accuracy_df\n",
    "    global y_data\n",
    "    global x_data\n",
    "    global Sub_score \n",
    "    global false_pos_df\n",
    "    global fig\n",
    "   \n",
    "    np.random.seed(46215423)\n",
    "    \n",
    "    real_score = np.zeros(243)\n",
    "    accuracy = np.zeros(243)\n",
    "    \n",
    "    false_pos_df = pd.DataFrame(columns = uncertainty_range, index= ['simulations in agreement with subject', 'simulations in disagreement with subject', 'Unreliable Subjects'])\n",
    "    \n",
    "    num_subj_unreliable = np.zeros(243) # keeps track of subjects whose score is unreliable under the assumed variation (0 is fine, 1 is unreliable)\n",
    "    false_pos_series=[]\n",
    "   \n",
    "    AD=0\n",
    "    NCI=0\n",
    "    Sub_score = pd.Series(real_score)\n",
    "    accuracy_df= pd.DataFrame(columns= uncertainty_range)\n",
    "    \n",
    "    \n",
    "    for i in range(len(uncertainty_range)):\n",
    "        false_pos = 0 # counter, stores number of points on second quadrant\n",
    "        false_neg = 0\n",
    "        true_pos = 0\n",
    "        true_neg = 0\n",
    "        FN = []\n",
    "        FP = []\n",
    "        TN = []\n",
    "        TP = []\n",
    "        \n",
    "        for j in range(243):\n",
    "            scores = run_sim_one_patient(Patients_df_zScore.iloc[:, j], uncertainty_range[i], num_runs)\n",
    "            y_0 = cl_score(linear_score(coefficients, Patients_df_zScore.iloc[:, j]))\n",
    "            x_data = np.ones_like(scores) * y_0\n",
    "            y_data = scores\n",
    "            colour = np.zeros_like(x_data)\n",
    "            false_neg = 0\n",
    "            false_pos = 0\n",
    "            true_neg=0\n",
    "            true_pos=0\n",
    "            for k in range(len(x_data)):\n",
    "                if x_data[k] > thresh and y_data[k] < thresh:\n",
    "                    false_neg = false_neg + 1\n",
    "                    num_subj_unreliable[j] = 1\n",
    "                elif x_data[k] < thresh and y_data[k]> thresh:\n",
    "                    false_pos = false_pos + 1\n",
    "                    num_subj_unreliable[j] = 1\n",
    "                elif x_data[k]> thresh and y_data[k] > thresh:\n",
    "                    true_pos = true_pos +1\n",
    "                elif x_data[k] < thresh and y_data[k] < thresh:\n",
    "                    true_neg = true_neg +1  \n",
    "\n",
    "            accuracy[j] = (num_runs-(false_neg)-(false_pos))/num_runs\n",
    "            real_score[j] = y_0\n",
    "\n",
    "\n",
    "            FN.append(false_neg)\n",
    "            FP.append(false_pos)\n",
    "            TN.append(true_neg)\n",
    "            TP.append(true_pos)\n",
    "        unreliable_subjects= str(np.sum(num_subj_unreliable))\n",
    "        accuracy_series = pd.Series(accuracy)\n",
    "        \n",
    "        disagreement = sum(FN) + sum(FP)\n",
    "        agreement= sum(TN) + sum(TP)\n",
    "       \n",
    "        accuracy_df[accuracy_df.columns[i]] = accuracy_series*100\n",
    "        false_pos_df[false_pos_df.columns[i]]= [agreement, disagreement, unreliable_subjects]\n",
    "        Sub_score = pd.Series(real_score)    \n",
    "        accuracy_df['Classifier Score']= Sub_score\n",
    "        \n",
    "        \n",
    "        dfm = accuracy_df.melt('Classifier Score', var_name='%RSD', value_name='Agreement')   \n",
    "    fig = sns.relplot(x= \"Classifier Score\" , y=\"Agreement\", hue='%RSD', data=dfm, kind='line', linewidth= 1, palette = \"rainbow\")\n",
    "    accuracy_df['Patient ID'] = patient_id\n",
    "    accuracy_df = accuracy_df.set_index('Patient ID')\n",
    "    for l in range (len(Sub_score)):\n",
    "            if Sub_score[l]>thresh:\n",
    "                AD= AD+1\n",
    "            else: NCI =NCI+1\n",
    "    return ( print(\"AD=\",AD), print(\"NCI=\",NCI), accuracy_df, false_pos_df, fig)\n",
    "\n",
    "\n",
    "sub_accuracy([25],thresh,100)\n",
    "\n",
    "accuracy_df\n",
    "\n",
    "disagreement_df=  accuracy_df[accuracy_df[25] < 100]\n",
    "disagreement_df = disagreement_df.sort_values(by= [25], ascending= False)\n",
    "disagreement_df.shape\n",
    "\n",
    "disagreement_df.to_csv(\"subject-wise disagreement.csv\")\n",
    "\n",
    "false_pos_df\n",
    "\n",
    "accuracy_df\n",
    "\n",
    "sub_accuracy([10, 25, 50], 0.86, 100)\n",
    "sub_accuracy([10, 25, 50], 0.90, 100)\n",
    "sub_accuracy([10, 25, 50], 0.80, 100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87264853-7fa1-41bf-b7f1-25ff180ae08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Import necessary libraries: pandas, numpy, matplotlib, and seaborn.\n",
    "\n",
    "2. Load a CSV file containing 243 subjects and their raw TPM counts across 1059 genes.\n",
    "\n",
    "3. Set the index row name to the gene id.\n",
    "\n",
    "4. Filter out rows that do not contain ERCC (a control protocol for validation of RNA sequencing).\n",
    "\n",
    "5. Store the coefficients (betas) of the linear classifier in an array.\n",
    "\n",
    "6. Filter out columns with patient data.\n",
    "\n",
    "7. Group columns by patient id and r1/r2 suffixes.\n",
    "\n",
    "8. Apply the mean function to the r1 and r2 columns for each group.\n",
    "\n",
    "9. Calculate the mean, standard deviation, and relative standard deviation (RSD) of each row.\n",
    "\n",
    "10. Define a function to compute the Z-score of each row.\n",
    "\n",
    "11. Compute and store the Z-scores.\n",
    "\n",
    "12. Define a sampling function performing the Monte Carlo simulations.\n",
    "\n",
    "13. Define a function to perform anti-logit operation on the linear score.\n",
    "\n",
    "14. Define a function to calculate subject wise mean and standard deviation of simulated scores.\n",
    "\n",
    "15. Define a function to calculate the classifier score for each simulation, corresponding to each subject.\n",
    "\n",
    "16. Define a function to calculate the linear score.\n",
    "\n",
    "17. Define a function to produce a scatter plot based on classifier scores of simulations against subject and count false positives and negatives.\n",
    "\n",
    "18. Define a function to calculate subject accuracy based on the number of simulations and produce dataframes with the accuracy and false positive/negative data.\n",
    "\n",
    "19. Calculate and output the subject accuracy for a given uncertainty range, threshold, and number of Monte Carlo simulations.\n",
    "\n",
    "20. Save the results to a CSV file.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5f0cf-573e-4fd2-b734-ac2e300d02aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
